\documentclass[12pt]{article}
%\usepackage[breaklinks=true]{hyperref}
\usepackage{color}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{natbib}
\usepackage{array}
\usepackage{booktabs, multicol, multirow}
\usepackage[nohead]{geometry}
\usepackage[singlespacing]{setspace}
\usepackage[bottom]{footmisc}
\usepackage{floatrow}
\usepackage{float,graphicx}
\usepackage{caption}
\usepackage{indentfirst}
\usepackage{lscape}
\usepackage{floatrow}
\usepackage{epsfig}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage[colorlinks=true,
            urlcolor=RawSienna,
            linkcolor=RawSienna,
            citecolor=NavyBlue]{hyperref}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{assumption}{Assumption}

\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}


\newcommand{\todo}[1]{{\color{red}{TO DO: \sc #1}}}

\newcommand{\reals}{\mathbb{R}}
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\naturals}{\mathbb{N}}
\newcommand{\rationals}{\mathbb{Q}}

\newcommand{\ind}{\mathbb{I}} % Indicator function
\newcommand{\pr}{\mathbb{P}} % Generic probability
\newcommand{\ex}{\mathbb{E}} % Generic expectation
\newcommand{\var}{\textrm{Var}}
\newcommand{\cov}{\textrm{Cov}}

\newcommand{\normal}{N} % for normal distribution (can probably skip this)
\newcommand{\eps}{\varepsilon}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand{\argmax}{\textrm{argmax}}
\newcommand{\argmin}{\textrm{argmin}}
\renewcommand{\baselinestretch}{1.5}

\begin{document}

\title{Simple Random Sampling: Not Simple}
\author{Kellie Ottoboni
\and
Ron L. Rivest
\and
Philip B.~Stark 
}

\date{draft \today}




\maketitle

\begin{abstract}
\small
A simple random sample (SRS) of size $k$ from a population of size $n$ is a sample drawn 
at random in such a way that every subset of $k$ of the $n$ items is equally likely to be selected. 
The theory of inference from SRSs is fundamental in statistics;
many statistical techniques and formulae assume that the data are an SRS.
True SRSs are rare; in practice, people tend to draw samples by using pseudo-random number generators 
(PRNGs) and algorithms that map a set of pseudo-random numbers into a subset of the population. 
Most statisticians take for granted that the software they use ``does the right thing,''
producing samples that can be treated as if they are SRSs.
In fact, the PRNG algorithm and the algorithm for drawing samples using the PRNG matter
enormously.
Using basic counting principles, we show that some widely used methods cannot generate all subsets of size $k$.
In simulations, we demonstrate that the subsets that they do generate do not have equal frequencies, which
introduces bias and makes uncertainty calculations meaningless.
We compare the ``randomness'' and computational efficiency of commonly-used PRNGs to a PRNG 
based on the SHA-256 hash function, which avoids these pitfalls because its state space is countably infinite.
We propose several best practices for researchers using PRNGs, including the wide adoption of hash function based PRNGs.
\end{abstract}

\section{Introduction}
Random sampling is one of the most fundamental tools in Statistics.
It is used to conduct surveys, including opinion surveys, population surveys like the census, and litigation; 
to run medical, agricultural, and marketing experiments; 
quality control in industry and auditing in finance and elections;
and countless other purposes.
Simple random sampling refers to drawing $k \leq n$ items from a population of $n$ items,
in such a way that each of ${n \choose k}$ subsets of size $k$ is equally likely.
Many standard statistical methods assume that the sample is drawn this way, 
or allocated between treatment and control groups this way
(e.g. $k$ of $n$ subjects are assigned to treatment, and the remaining $n-k$ to control).

\begin{itemize}
\item We examine methods for drawing pseudo-random simple random samples. 
We include a discussion of pseudo-random number generators (PRNGs) and 
of algorithms used to select samples using PRNGs.
Among other things, we find bounds on the number of samples that can be generated 
using a variate of PRNGs, for a number of sampling algorithms. 
We also consider how that affects the bias and uncertainty of estimates based on pseudo-random
samples rather than on actual simple random samples.
\item PRNGs considered include linear congruential generators (LCGs, including RANDU)
and the Mersenne Twister. We discuss using cryptographic hash functions to generate PRNs.
\item We conclude with recommendations for best practices using PRNGs to generate random samples.
\end{itemize}



\section{Background}
\subsection{Definition of ``random'' numbers}
Most computers lack the hardware needed to generate truly random numbers. 
Instead, they use algorithms called pseudo-random number generators (PRNGs) to generate
deterministic sequences from an initial ``seed,'' which generally can be set by the user,
for instance to an externally generated random value.
Each time a number is generated, the PRNG's ``state'' changes.

Depending on the quality of the PRNG, the sequences behave more or less like sequences of random numbers.
How does one gauge ``how random'' sequences from a PRNG are?
A PRNG yields sequences of random numbers on the interval $[0, 1]$ or over the binary set $\{0, 1\}$.
The sequences output by such PRNGs should be statistically indistinguishable from IID $U(0,1)$ sequences or
IID Bernoulli$(1/2)$ sequences, respectively.
The tests for the bit sequence case applies to the $U(0,1)$ case as well, because there is a one-to-one relationship
between sequences of bits and integers.
Namely, every sequence of $k$ bits corresponds to an integer on $0, 1, \dots, 2^k-1$, and scaling by $2^k$
yields a unique value on $[0, 1)$. (cite L'Ecuyer, Simard)

There are a multitude of ways to test the hypothesis that sequences from a PRNG are indistinguishable 
from random sequences.
\todo{list types of tests + citations: L'Ecuyer Simard TestU01 (2007),  Knuth (1969), Marsaglia DIEHARD tests (1968), NIST tests

\begin{itemize}
\item Two notions of uniformity: 1) uniformly distributed within a sequence with a fixed starting state, 2) the set of sequences of length $t$ that can be hit by the PRNG should be uniformly distributed among the set of all sequences of length $t$ -- this gets at the SRS problem
\end{itemize}
}

\subsection{Sampling algorithms}
A simple random sample of size $k$ from a population of size $n$ is a sample drawn in such a way that each of the ${n \choose k}$ possible subsets of size $k$ is equally likely.
Given a good source of randomness, there are many ways to operationalize this definition to draw simple random samples.
\subsubsection{Algorithm PIKK (permute indices and keep $k$)}
One basic approach is like shuffling a deck of $n$ cards, then dealing the top $k$: permute the population at random, then take the first $k$ elements of the permutation to be the sample.
There are a number of standard ways to generate a random permutation -- i.e., to shuffle the deck.
If we had a way to generate independent, identically distributed (iid) $U[0,1]$ random numbers, we could sample $k$ out of $n$ as follows:
\todo{create an algorithm environment}
Algorithm PIKK
\begin{itemize}
\item assign iid $U[0,1]$ numbers to the $n$ elements of the population
\item the sample consists of the $k$ items assigned the smallest random numbers (break ties randomly)
\item amounts to generating a random permutation of the population, then taking first $k$.
\item if the numbers really are iid, every permutation is equally likely, and it follows that the first $k$ are an SRS
requires $n$ random numbers (and sorting)
\end{itemize}

This algorithm is inefficient: it requires the generation of $n$ random numbers and then a sorting operation.

\subsubsection{Shuffle}
There are more efficient ways to generate a random permutation than assigning a number to each element and sorting.
One example is the "Fisher-Yates shuffle" or "Knuth shuffle" (Knuth attributes it to Durstenfeld).

\begin{verbatim}
Algorithm Fisher-Yates-Knuth-Durstenfeld shuffle (backwards version)
for i=1, ..., n-1:
    J <- random integer uniformly distributed on {i, ..., n}
    (a[J], a[i]) <- (a[i], a[J])
\end{verbatim}

This algorithm requires the ability to generate independent random integers on various ranges, but doesn't require sorting.
There is also a version suitable for streaming, i.e. generating a random permutation of a list that has an (initially) unknown number of elements.

\begin{verbatim}
Algorithm Fisher-Yates-Knuth-Durstenfeld shuffle (streaming version)
i <- 0
a = []
while there are records left:
    i <- i+1
    J <- random integer uniformly distributed on {1, ..., i}
    if J < i:
        a[i] <- a[J]
        a[J] <- next record
    else:
        a[i] <- next record

\end{verbatim}

\begin{proof}[Proof that the streaming shuffle works]
We prove by induction. The base case $i=1$ is trivial.
At stage $i$, $i>1$, suppose that all $(i-1)!$ permutations of $\{1, 2, \dots, i-1\}$ are equally likely.
$J$ may take on $i-1$ distinct values less than $i$, and the swapping procedure thus yields $(i-1)! \times (i-1)$
possible distinct permutations.
If $J = i$, then there is no swap and $(i-1)$ possible distinct permutations.
In total, there are $(i-1)! \times (i-1 + 1) = i!$ possible distinct permutations, and all are equally likely because
all values of $J$ and permutations of the first $(i-1)$ elements were equally likely.
\end{proof}


\subsubsection{Algorithm \texttt{Random\_Sample} from Cormen et al \todo{cite}}
This is a recursive algorithm that requires only $k$ random integers and does not require sorting.
\todo{turn into pseudocode; prove by recursion that the method works}
\begin{verbatim}
def Random_Sample(n, k, gen=np.random):  # from Cormen et al.
    if k==0:
        return set()
    else:
        S = Random_Sample(n-1, k-1)
        i = gen.randint(1,n) 
        if i in S:
            S = S.union([n])
        else:
            S = S.union([i])
    return S
\end{verbatim}

\section{Instances of problems}
The sampling algorithms in the previous section rely on the ability to generate random integers uniformly distributed 
on various ranges.
In this section, we illustrate several known failures in common software packages.
 

\subsection{RANDU and LCGs}

\subsection{Stata software}
\subsection{Random integer generation in R}

\section{Results}
\subsection{Pigeonhole arguments}
\subsection{Simulations showing bias}
\section{Hash-function based RNGs}
\section{Discussion}
\subsection{Best Practices}
\section{Conclusions}




\end{document}
